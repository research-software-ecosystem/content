{
    "accessibility": "Open access",
    "additionDate": "2022-09-28T18:22:52.489167Z",
    "biotoolsCURIE": "biotools:sparkgc",
    "biotoolsID": "sparkgc",
    "confidence_flag": "tool",
    "cost": "Free of charge",
    "credit": [
        {
            "email": "jiym@njupt.edu.cn",
            "name": "Yimu Ji",
            "typeEntity": "Person"
        },
        {
            "name": "Guangyong Hu"
        },
        {
            "name": "Haichang Yao"
        },
        {
            "name": "Houzhi Fang"
        },
        {
            "name": "Shangdong Liu"
        }
    ],
    "description": "Spark based genome compression for large collections of genomes.",
    "editPermission": {
        "type": "private"
    },
    "function": [
        {
            "operation": [
                {
                    "term": "Genome indexing",
                    "uri": "http://edamontology.org/operation_3211"
                }
            ]
        }
    ],
    "homepage": "https://github.com/haichangyao/SparkGC",
    "language": [
        "Java"
    ],
    "lastUpdate": "2022-09-28T18:29:52.597948Z",
    "license": "Not licensed",
    "name": "SparkGC",
    "operatingSystem": [
        "Linux"
    ],
    "owner": "Jennifer",
    "publication": [
        {
            "doi": "10.1186/S12859-022-04825-5",
            "metadata": {
                "abstract": "© 2022, The Author(s).Since the completion of the Human Genome Project at the turn of the century, there has been an unprecedented proliferation of sequencing data. One of the consequences is that it becomes extremely difficult to store, backup, and migrate enormous amount of genomic datasets, not to mention they continue to expand as the cost of sequencing decreases. Herein, a much more efficient and scalable program to perform genome compression is required urgently. In this manuscript, we propose a new Apache Spark based Genome Compression method called SparkGC that can run efficiently and cost-effectively on a scalable computational cluster to compress large collections of genomes. SparkGC uses Spark’s in-memory computation capabilities to reduce compression time by keeping data active in memory between the first-order and second-order compression. The evaluation shows that the compression ratio of SparkGC is better than the best state-of-the-art methods, at least better by 30%. The compression speed is also at least 3.8 times that of the best state-of-the-art methods on only one worker node and scales quite well with the number of nodes. SparkGC is of significant benefit to genomic data storage and transmission. The source code of SparkGC is publicly available at https://github.com/haichangyao/SparkGC.",
                "authors": [
                    {
                        "name": "Fang H."
                    },
                    {
                        "name": "Hu G."
                    },
                    {
                        "name": "Ji Y."
                    },
                    {
                        "name": "Liu S."
                    },
                    {
                        "name": "Yao H."
                    }
                ],
                "date": "2022-12-01T00:00:00Z",
                "journal": "BMC Bioinformatics",
                "title": "SparkGC: Spark based genome compression for large collections of genomes"
            },
            "pmcid": "PMC9310413",
            "pmid": "35879669"
        }
    ],
    "toolType": [
        "Command-line tool"
    ],
    "topic": [
        {
            "term": "Genomics",
            "uri": "http://edamontology.org/topic_0622"
        },
        {
            "term": "Human biology",
            "uri": "http://edamontology.org/topic_2815"
        },
        {
            "term": "Mapping",
            "uri": "http://edamontology.org/topic_0102"
        }
    ]
}

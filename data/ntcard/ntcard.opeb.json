{"credit":[{"email":"hmohamadi@bcgsc.ca","name":"Hamid Mohamadi","typeEntity":"Person","typeRoles":["Primary contact"]},{"email":"ibirol@bcgsc.ca","name":"Inanc Birol","typeEntity":"Person","typeRoles":["Primary contact"]}],"documentation":[{"type":"GENERAL","url":"https://github.com/bcgsc/ntCard"}],"function":[{"operation":[{"term":"k-mer counting","uri":"http://edamontology.org/operation_3472"}]}],"labels":{"language":["C++"],"license":"GPL-3.0","operatingSystem":["Linux","Mac"],"toolType":["Command-line tool"],"topic":[{"term":"Genomics","uri":"http://edamontology.org/topic_0622"},{"term":"Sequence analysis","uri":"http://edamontology.org/topic_0080"},{"term":"Sequencing","uri":"http://edamontology.org/topic_3168"}]},"publication":[{"abstract":"© The Author 2017. Published by Oxford University Press. Motivation: Many bioinformatics algorithms are designed for the analysis of sequences of some uniform length, conventionally referred to as/c-mers. These include de Bruijn graph assembly methods and sequence alignment tools. An efficient algorithm to enumerate the number of unique/c-mers, or even better, to build a histogram of/c-mer frequencies would be desirable for these tools and their downstream analysis pipelines. Among other applications, estimated frequencies can be used to predict genome sizes, measure sequencing error rates, and tune runtime parameters for analysis tools. However, calculating a/c-mer histogram from large volumes of sequencing data is a challenging task. Results: Here, we present ntCard, a streaming algorithm for estimating the frequencies of/c-mers in genomics datasets. At its core, ntCard uses the ntHash algorithm to efficiently compute hash values for streamed sequences. It then samples the calculated hash values to build a reduced representation multiplicity table describing the sample distribution. Finally, it uses a statistical model to reconstruct the population distribution from the sample distribution. We have compared the performance of ntCard and other cardinality estimation algorithms. We used three datasets of 480 GB, 500 GB and 2.4 TB in size, where the first two representing whole genome shotgun sequencing experiments on the human genome and the last one on the white spruce genome. Results show ntCard estimates/c-mer coverage frequencies >15× faster than the state-of-the-art algorithms, using similar amount of memory, and with higher accuracy rates. Thus, our benchmarks demonstrate ntCard as a potentially enabling technology for large-scale genomics applications.","authors":["Mohamadi H.","Khan H.","Birol I."],"cit_count":8,"doi":"10.1093/bioinformatics/btw832","journal":"Bioinformatics","title":"ntCard: A streaming algorithm for cardinality estimation in genomics data","year":"2017-05-01"}],"summary":{"biotoolsCURIE":"biotools:ntcard","biotoolsID":"ntcard","description":"Streaming algorithm for cardinality estimation in genomics data.","homepage":"https://github.com/bcgsc/ntCard","name":"ntCard"}}
{
  "@context": {
    "biotools": "https://bio.tools/ontology/",
    "bsc": "http://bioschemas.org/",
    "edam": "http://edamontology.org/",
    "rdf": "http://www.w3.org/1999/02/22-rdf-syntax-ns#",
    "rdfs": "http://www.w3.org/2000/01/rdf-schema#",
    "sc": "http://schema.org/",
    "xsd": "http://www.w3.org/2001/XMLSchema#"
  },
  "@graph": [
    {
      "@id": "https://doi.org/10.1109/TVCG.2019.2934307",
      "@type": "sc:CreativeWork"
    },
    {
      "@id": "https://bio.tools/TensorFlow.js",
      "@type": "sc:SoftwareApplication",
      "sc:citation": [
        {
          "@id": "https://doi.org/10.1109/TVCG.2019.2934307"
        },
        "pubmed:31449023"
      ],
      "sc:description": "> LOW CONFIDENCE! | > HOMEPAGE BROKEN! | > CORRECT NAME OF TOOL COULD ALSO BE 't-SNE', 'splatting', 'reformulate t-SNE', 'reformulate' | GPGPU Linear Complexity t-SNE Optimization | In recent years the t-distributed Stochastic Neighbor Embedding (t-SNE) algorithm has become one of the most used and insightful techniques for exploratory data analysis of high-dimensional data. It reveals clusters of high-dimensional data points at different scales while only requiring minimal tuning of its parameters. However, the computational complexity of the algorithm limits its application to relatively small datasets. To address this problem, several evolutions of t-SNE have been developed in recent years, mainly focusing on the scalability of the similarity computations between data points. However, these contributions are insufficient to achieve interactive rates when visualizing the evolution of the t-SNE embedding for large datasets",
      "sc:name": "TensorFlow.js",
      "sc:url": "http://TensorFlow.js"
    }
  ]
}
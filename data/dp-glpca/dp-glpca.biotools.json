{
    "additionDate": "2021-01-18T10:38:53Z",
    "biotoolsCURIE": "biotools:dp-glpca",
    "biotoolsID": "dp-glpca",
    "confidence_flag": "tool",
    "description": "Dissimilarity propagation-guided graph-Laplacian principal component analysis (DP-GLPCA) is a model for constrained clustering. By fully utilizing a limited number of weakly supervisory information in the form of pairwise constraints, the proposed DP-GLPCA is capable of capturing both the local and global structures of input samples to exploit their characteristics for excellent clustering.",
    "editPermission": {
        "type": "private"
    },
    "function": [
        {
            "operation": [
                {
                    "term": "Clustering",
                    "uri": "http://edamontology.org/operation_3432"
                },
                {
                    "term": "Dimensionality reduction",
                    "uri": "http://edamontology.org/operation_3935"
                },
                {
                    "term": "Essential dynamics",
                    "uri": "http://edamontology.org/operation_3891"
                }
            ]
        }
    ],
    "homepage": "https://github.com/jyh-learning/DP-GLPCA",
    "language": [
        "C++",
        "MATLAB"
    ],
    "lastUpdate": "2021-03-11T14:38:47Z",
    "name": "DP-GLPCA",
    "owner": "Kigaard",
    "publication": [
        {
            "doi": "10.1109/TNNLS.2020.3016397",
            "metadata": {
                "abstract": "Â© 2012 IEEE.In this article, we propose a novel model for constrained clustering, namely, the dissimilarity propagation-guided graph-Laplacian principal component analysis (DP-GLPCA). By fully utilizing a limited number of weakly supervisory information in the form of pairwise constraints, the proposed DP-GLPCA is capable of capturing both the local and global structures of input samples to exploit their characteristics for excellent clustering. More specifically, we first formulate a convex semisupervised low-dimensional embedding model by incorporating a new dissimilarity regularizer into GLPCA (i.e., an unsupervised dimensionality reduction model), in which both the similarity and dissimilarity between low-dimensional representations are enforced with the constraints to improve their discriminability. An efficient iterative algorithm based on the inexact augmented Lagrange multiplier is designed to solve it with the global convergence guaranteed. Furthermore, we innovatively propose to propagate the cannot-link constraints (i.e., dissimilarity) to refine the dissimilarity regularizer to be more informative. The resulting DP model is iteratively solved, and we also prove that it can converge to a Karush-Kuhn-Tucker point. Extensive experimental results over nine commonly used benchmark data sets show that the proposed DP-GLPCA can produce much higher clustering accuracy than state-of-the-art constrained clustering methods. Besides, the effectiveness and advantage of the proposed DP model are experimentally verified. To the best of our knowledge, it is the first time to investigate DP, which is contrast to existing pairwise constraint propagation that propagates similarity. The code is publicly available at https://github.com/jyh-learning/DP-GLPCA.",
                "authors": [
                    {
                        "name": "Hou J."
                    },
                    {
                        "name": "Jia Y."
                    },
                    {
                        "name": "Kwong S."
                    }
                ],
                "date": "2021-09-01T00:00:00Z",
                "journal": "IEEE Transactions on Neural Networks and Learning Systems",
                "title": "Constrained Clustering with Dissimilarity Propagation-Guided Graph-Laplacian PCA"
            },
            "pmid": "32853153"
        }
    ],
    "toolType": [
        "Script"
    ]
}

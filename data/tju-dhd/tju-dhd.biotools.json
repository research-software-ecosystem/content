{
    "additionDate": "2021-01-18T12:01:20Z",
    "biotoolsCURIE": "biotools:tju-dhd",
    "biotoolsID": "tju-dhd",
    "confidence_flag": "tool",
    "description": "A Diverse High-Resolution Dataset for Object Detection.",
    "editPermission": {
        "type": "private"
    },
    "function": [
        {
            "operation": [
                {
                    "term": "Aggregation",
                    "uri": "http://edamontology.org/operation_3436"
                },
                {
                    "term": "Image analysis",
                    "uri": "http://edamontology.org/operation_3443"
                },
                {
                    "term": "Validation",
                    "uri": "http://edamontology.org/operation_2428"
                }
            ]
        }
    ],
    "homepage": "https://github.com/tjubiit/TJU-DHD",
    "lastUpdate": "2021-02-27T10:19:06Z",
    "license": "MIT",
    "name": "TJU-DHD",
    "owner": "zsmag19",
    "publication": [
        {
            "doi": "10.1109/TIP.2020.3034487",
            "metadata": {
                "abstract": "Vehicles, pedestrians, and riders are the most important and interesting objects for the perception modules of self-driving vehicles and video surveillance. However, the state-of-the-art performance of detecting such important objects (esp. small objects) is far from satisfying the demand of practical systems. Large-scale, rich-diversity, and high-resolution datasets play an important role in developing better object detection methods to satisfy the demand. Existing public large-scale datasets such as MS COCO collected from websites do not focus on the specific scenarios. Moreover, the popular datasets (e.g., KITTI and Citypersons) collected from the specific scenarios are limited in the number of images and instances, the resolution, and the diversity. To attempt to solve the problem, we build a diverse high-resolution dataset (called TJU-DHD). The dataset contains 115354 high-resolution images (52% images have a resolution of 1624\u00d71200 pixels and 48% images have a resolution of at least 2, 560\u00d71.440 pixels) and 709 330 labeled objects in total with a large variance in scale and appearance. Meanwhile, the dataset has a rich diversity in season variance, illumination variance, and weather variance. In addition, a new diverse pedestrian dataset is further built. With the four different detectors (i.e., the one-stage RetinaNet, anchor-free FCOS, two-stage FPN, and Cascade R-CNN), experiments about object detection and pedestrian detection are conducted. We hope that the newly built dataset can help promote the research on object detection and pedestrian detection in these two scenes. The dataset is available at https://github.com/tjubiit/TJU-DHD.",
                "authors": [
                    {
                        "name": "Pang Y."
                    },
                    {
                        "name": "Cao J."
                    },
                    {
                        "name": "Li Y."
                    },
                    {
                        "name": "Xie J."
                    },
                    {
                        "name": "Sun H."
                    },
                    {
                        "name": "Gong J."
                    }
                ],
                "citationCount": 2,
                "date": "2021-01-01T00:00:00Z",
                "journal": "IEEE transactions on image processing : a publication of the IEEE Signal Processing Society",
                "title": "TJU-DHD: A Diverse High-Resolution Dataset for Object Detection"
            },
            "pmid": "33141669"
        }
    ],
    "topic": [
        {
            "term": "Imaging",
            "uri": "http://edamontology.org/topic_3382"
        },
        {
            "term": "Proteomics experiment",
            "uri": "http://edamontology.org/topic_3520"
        },
        {
            "term": "Transcription factors and regulatory sites",
            "uri": "http://edamontology.org/topic_0749"
        }
    ]
}
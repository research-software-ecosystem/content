{
    "additionDate": "2019-11-14T20:07:49Z",
    "biotoolsCURIE": "biotools:Super-Resolution",
    "biotoolsID": "Super-Resolution",
    "confidence_flag": "tool",
    "description": "Image Super-Resolution as a Defense Against Adversarial Attacks | super-resolution-adversarial-defense | We use wavelet denoising and image super resolution as pre-processing steps to defend images against adversarial attacks. If you find our work useful in your research or publication, please cite our work:",
    "editPermission": {
        "type": "public"
    },
    "function": [
        {
            "operation": [
                {
                    "term": "Deisotoping",
                    "uri": "http://edamontology.org/operation_3629"
                }
            ]
        }
    ],
    "homepage": "https://github.com/aamir-mustafa/super-resolution-adversarial-defense",
    "language": [
        "Python"
    ],
    "lastUpdate": "2020-12-27T12:18:19Z",
    "name": "Super-Resolution",
    "owner": "Pub2Tools",
    "publication": [
        {
            "doi": "10.1109/TIP.2019.2940533",
            "metadata": {
                "abstract": "\u00a9 1992-2012 IEEE.Convolutional Neural Networks have achieved significant success across multiple computer vision tasks. However, they are vulnerable to carefully crafted, human-imperceptible adversarial noise patterns which constrain their deployment in critical security-sensitive systems. This paper proposes a computationally efficient image enhancement approach that provides a strong defense mechanism to effectively mitigate the effect of such adversarial perturbations. We show that deep image restoration networks learn mapping functions that can bring off-the-manifold adversarial samples onto the natural image manifold, thus restoring classification towards correct classes. A distinguishing feature of our approach is that, in addition to providing robustness against attacks, it simultaneously enhances image quality and retains models performance on clean images. Furthermore, the proposed method does not modify the classifier or requires a separate mechanism to detect adversarial images. The effectiveness of the scheme has been demonstrated through extensive experiments, where it has proven a strong defense in gray-box settings. The proposed scheme is simple and has the following advantages: 1) it does not require any model training or parameter optimization, 2) it complements other existing defense mechanisms, 3) it is agnostic to the attacked model and attack type, and 4) it provides superior performance across all popular attack algorithms. Our codes are publicly available at https://github.com/aamir-mustafa/super-resolution-adversarial-defense.",
                "authors": [
                    {
                        "name": "Mustafa A."
                    },
                    {
                        "name": "Khan S.H."
                    },
                    {
                        "name": "Hayat M."
                    },
                    {
                        "name": "Shen J."
                    },
                    {
                        "name": "Shao L."
                    }
                ],
                "citationCount": 12,
                "date": "2020-01-01T00:00:00Z",
                "journal": "IEEE Transactions on Image Processing",
                "title": "Image super-resolution as a defense against adversarial attacks"
            },
            "pmid": "31545722"
        }
    ],
    "topic": [
        {
            "term": "Medical imaging",
            "uri": "http://edamontology.org/topic_3384"
        },
        {
            "term": "Machine learning",
            "uri": "http://edamontology.org/topic_3474"
        },
        {
            "term": "RNA immunoprecipitation",
            "uri": "http://edamontology.org/topic_3794"
        }
    ],
    "validated": 1
}
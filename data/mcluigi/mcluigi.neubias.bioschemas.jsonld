{
  "@context": {
    "dc": "http://dcterms/",
    "rdf": "http://www.w3.org/1999/02/22-rdf-syntax-ns#",
    "rdfs": "http://www.w3.org/2000/01/rdf-schema#",
    "xsd": "http://www.w3.org/2001/XMLSchema#"
  },
  "@id": "http://biii.eu/node/1199",
  "@type": "http://schema.org/SoftwareApplication",
  "http://schema.org/applicationCategory": [
    {
      "@id": "http://edamontology.org/operation_2990"
    },
    {
      "@id": "http://edamontology.org/operation__RyCFuPLOeGxpcGjYbWcWWD"
    },
    {
      "@id": "http://edamontology.org/operation_Image_segmentation"
    }
  ],
  "http://schema.org/citation": [
    {
      "@id": "https://www.nature.com/articles/nmeth.4151"
    },
    "Beier et al. \"Multicut brings automated neurite segmentation closer to human performance\""
  ],
  "http://schema.org/dateCreated": "2018-01-30T15:32:42",
  "http://schema.org/dateModified": "2018-01-30T15:39:33",
  "http://schema.org/description": "<p>Multicut workflow for large connectomics data. Using luigi for pipelining and caching processing steps. Most of the computations are done out-of-core using hdf5 as backend and implementations from nifty</p>\r\n",
  "http://schema.org/featureList": [
    {
      "@id": "http://edamontology.org/operation_Image_segmentation"
    },
    {
      "@id": "http://edamontology.org/operation_2990"
    },
    {
      "@id": "http://edamontology.org/operation__RyCFuPLOeGxpcGjYbWcWWD"
    }
  ],
  "http://schema.org/license": "MIT",
  "http://schema.org/name": "McLuigi",
  "http://schema.org/publisher": "Pape Constantin",
  "http://schema.org/softwareRequirements": [
    {
      "@id": "http://biii.eu/node/1198"
    },
    {
      "@id": "http://biii.eu/node/73"
    }
  ]
}
{
    "additionDate": "2021-01-18T11:55:15Z",
    "biotoolsCURIE": "biotools:dtoolai",
    "biotoolsID": "dtoolai",
    "confidence_flag": "tool",
    "credit": [
        {
            "email": "matthew.hartley@jic.ac.uk",
            "name": "Matthew Hartley",
            "typeEntity": "Person"
        }
    ],
    "description": "dtoolAI is a library for supporting reproducible deep learning.",
    "documentation": [
        {
            "type": [
                "User manual"
            ],
            "url": "https://dtoolai.readthedocs.io"
        }
    ],
    "editPermission": {
        "type": "private"
    },
    "function": [
        {
            "operation": [
                {
                    "term": "Data retrieval",
                    "uri": "http://edamontology.org/operation_2422"
                },
                {
                    "term": "Network analysis",
                    "uri": "http://edamontology.org/operation_3927"
                },
                {
                    "term": "Standardisation and normalisation",
                    "uri": "http://edamontology.org/operation_3435"
                }
            ]
        }
    ],
    "homepage": "https://github.com/jic-csb/dtoolai",
    "language": [
        "Python"
    ],
    "lastUpdate": "2021-03-03T20:36:50Z",
    "license": "MIT",
    "name": "dtoolAI",
    "owner": "Kigaard",
    "publication": [
        {
            "doi": "10.1016/J.PATTER.2020.100073",
            "metadata": {
                "abstract": "© 2020 The AuthorsDeep learning, a set of approaches using artificial neural networks, has generated rapid recent advancements in machine learning. Deep learning does, however, have the potential to reduce the reproducibility of scientific results. Model outputs are critically dependent on the data and processing approach used to initially generate the model, but this provenance information is usually lost during model training. To avoid a future reproducibility crisis, we need to improve our deep-learning model management. The FAIR principles for data stewardship and software/workflow implementation give excellent high-level guidance on ensuring effective reuse of data and software. We suggest some specific guidelines for the generation and use of deep-learning models in science and explain how these relate to the FAIR principles. We then present dtoolAI, a Python package that we have developed to implement these guidelines. The package implements automatic capture of provenance information during model training and simplifies model distribution. Science has made use of machine learning, a way of teaching computers to understand patterns in data, for a long time. Deep learning, based on the way that real brains process data, has brought enormous improvements in the speed and accuracy of image and language processing over the last few years. However, the “black box” nature of deep-learning models makes scientific analyses that make use of them difficult to reproduce. In this work, we show how we might be able to improve long-term reproducibility for data analyses that rely on deep-learning models. We do this by giving guidance on how specific aspects of the FAIR principles for data management can be applied to training and using these models. We also present dtoolAI, a software tool and code library we have developed. We hope that in the future, adoption of our guidelines or similar principles will improve our collective trust in results that arise from deep learning. Deep learning has brought impressive advances in our ability to extract information from data. However, models produced by these techniques are often difficult to reproduce or interpret. We provide guidelines for improving the reproducibility of deep-learning models, together with the Python package dtoolAI, a proof-of-concept implementation of these guidelines.",
                "authors": [
                    {
                        "name": "Hartley M."
                    },
                    {
                        "name": "Olsson T.S.G."
                    }
                ],
                "citationCount": 2,
                "date": "2020-08-14T00:00:00Z",
                "journal": "Patterns",
                "title": "dtoolAI: Reproducibility for Deep Learning"
            },
            "pmcid": "PMC7660391",
            "pmid": "33205122"
        }
    ],
    "toolType": [
        "Library"
    ],
    "topic": [
        {
            "term": "Data governance",
            "uri": "http://edamontology.org/topic_3571"
        },
        {
            "term": "Machine learning",
            "uri": "http://edamontology.org/topic_3474"
        },
        {
            "term": "Workflows",
            "uri": "http://edamontology.org/topic_0769"
        }
    ]
}

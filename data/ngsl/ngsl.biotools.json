{
    "additionDate": "2020-01-14T09:31:05Z",
    "biotoolsCURIE": "biotools:NGSL",
    "biotoolsID": "NGSL",
    "confidence_flag": "tool",
    "description": "Guide Subspace Learning for Unsupervised Domain Adaptation.\n\nGuided Subspace Learning(GSL demo).\n\nIn the file, there are multiple .m files.\n\nNGSL.m : Core codes of NGSL algorithm.\n\nGSL.m : Core codes of GSL algorithm.",
    "editPermission": {
        "type": "public"
    },
    "homepage": "https://github.com/Fjr9516/GSL",
    "language": [
        "MATLAB",
        "C++",
        "Python",
        "C"
    ],
    "lastUpdate": "2021-01-04T08:16:26Z",
    "name": "NGSL",
    "owner": "Pub2Tools",
    "publication": [
        {
            "doi": "10.1109/TNNLS.2019.2944455",
            "metadata": {
                "abstract": "\u00a9 2012 IEEE.A prevailing problem in many machine learning tasks is that the training (i.e., source domain) and test data (i.e., target domain) have different distribution [i.e., non-independent identical distribution (i.i.d.)]. Unsupervised domain adaptation (UDA) was proposed to learn the unlabeled target data by leveraging the labeled source data. In this article, we propose a guide subspace learning (GSL) method for UDA, in which an invariant, discriminative, and domain-agnostic subspace is learned by three guidance terms through a two-stage progressive training strategy. First, the subspace-guided term reduces the discrepancy between the domains by moving the source closer to the target subspace. Second, the data-guided term uses the coupled projections to map both domains to a unified subspace, where each target sample can be represented by the source samples with a low-rank coefficient matrix that can preserve the global structure of data. In this way, the data from both domains can be well interlaced and the domain-invariant features can be obtained. Third, for improving the discrimination of the subspaces, the label-guided term is constructed for prediction based on source labels and pseudo-target labels. To further improve the model tolerance to label noise, a label relaxation matrix is introduced. For the solver, a two-stage learning strategy with teacher teaches and student feedbacks mode is proposed to obtain the discriminative domain-agnostic subspace. In addition, for handling nonlinear domain shift, a nonlinear GSL (NGSL) framework is formulated with kernel embedding, such that the unified subspace is imposed with nonlinearity. Experiments on various cross-domain visual benchmark databases show that our methods outperform many state-of-the-art UDA methods. The source code is available at https://github.com/Fjr9516/GSL.",
                "authors": [
                    {
                        "name": "Zhang L."
                    },
                    {
                        "name": "Fu J."
                    },
                    {
                        "name": "Wang S."
                    },
                    {
                        "name": "Zhang D."
                    },
                    {
                        "name": "Dong Z."
                    },
                    {
                        "name": "Philip Chen C.L."
                    }
                ],
                "citationCount": 8,
                "date": "2020-09-01T00:00:00Z",
                "journal": "IEEE Transactions on Neural Networks and Learning Systems",
                "title": "Guide Subspace Learning for Unsupervised Domain Adaptation"
            },
            "pmid": "31689213"
        }
    ],
    "toolType": [
        "Command-line tool"
    ],
    "topic": [
        {
            "term": "Machine learning",
            "uri": "http://edamontology.org/topic_3474"
        }
    ],
    "validated": 1
}
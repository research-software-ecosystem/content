
{
    "credit": [
    ],
    "function": [
        {
            "operation": [
                {
                    "term": "Microscope image visualisation",
                    "uri": "http://edamontology.org/operation_3552"
                },
                {
                    "term": "Neurite measurement",
                    "uri": "http://edamontology.org/operation_3450"
                },
                {
                    "term": "Single particle analysis",
                    "uri": "http://edamontology.org/operation_3457"
                }
            ]
        }
    ],
    "labels": {
        "topic": [
            {
                "term": "Imaging",
                "uri": "http://edamontology.org/topic_3382"
            },
            {
                "term": "Machine learning",
                "uri": "http://edamontology.org/topic_3474"
            },
            {
                "term": "Model organisms",
                "uri": "http://edamontology.org/topic_0621"
            }
        ]
    },
    "link": [
        {
            "type": "Other",
            "url": "http://bit.ly/deep-z"
        }
    ],
    "publication": [
        {
            "abstract": "© 2019, The Author(s), under exclusive licence to Springer Nature America, Inc.We demonstrate that a deep neural network can be trained to virtually refocus a two-dimensional fluorescence image onto user-defined three-dimensional (3D) surfaces within the sample. Using this method, termed Deep-Z, we imaged the neuronal activity of a Caenorhabditis elegans worm in 3D using a time sequence of fluorescence images acquired at a single focal plane, digitally increasing the depth-of-field by 20-fold without any axial scanning, additional hardware or a trade-off of imaging resolution and speed. Furthermore, we demonstrate that this approach can correct for sample drift, tilt and other aberrations, all digitally performed after the acquisition of a single fluorescence image. This framework also cross-connects different imaging modalities to each other, enabling 3D refocusing of a single wide-field fluorescence image to match confocal microscopy images acquired at different sample planes. Deep-Z has the potential to improve volumetric imaging speed while reducing challenges relating to sample drift, aberration and defocusing that are associated with standard 3D fluorescence microscopy.",
            "authors": [
                "Wu Y.",
                "Rivenson Y.",
                "Wang H.",
                "Luo Y.",
                "Ben-David E.",
                "Bentolila L.A.",
                "Pritz C.",
                "Ozcan A."
            ],
            "cit_count": 0,
            "doi": "10.1038/S41592-019-0622-5",
            "journal": "Nature Methods",
            "pmid": "31686039",
            "title": "Three-dimensional virtual refocusing of fluorescence microscopy images using deep learning",
            "year": "2019-12-01"
        }
    ],
    "summary": {
        "biotoolsCURIE": "biotools:Deep-Z",
        "biotoolsID": "Deep-Z",
        "description": "Three-dimensional virtual refocusing of fluorescence microscopy images using deep learning.\n\nDeepZ Plugin Release_v1.3 – Google Drev.\n\nThree-dimensional propagation and time-reversal of fluorescence images.\n\nNeural network learns fluorescence wave propagation and time-reversal to propagate a 2D fluorescence image onto user-defined 3D surfaces, enabling 3D imaging of fluorescent samples using a single 2D image, without mechanical scanning, additional hardware, or a trade-off of resolution or speed. For details, refer to our publication \"Three-dimensional propagation and time-reversal of fluorescence images\" [1]. (Video below: 3D reconstruction of a C. elegans using Deep-Z inference)",
        "homepage": "http://bit.ly/deep-z-git",
        "name": "Deep-Z"
    }
}
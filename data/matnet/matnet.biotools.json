{
    "additionDate": "2021-01-18T10:36:01Z",
    "biotoolsCURIE": "biotools:matnet",
    "biotoolsID": "matnet",
    "confidence_flag": "tool",
    "description": "Motion-Attentive Transition Network for Zero-Shot Video Object Segmentation.\n\nMotion-Attentive Transition for Zero-Shot Video Object Segmentation.\n\n[2020/06/15] Update results for DAVIS-17 test-dev set!.\n\nThis is a PyTorch implementation of our MATNet for unsupervised video object segmentation.\n\n[2020/03/04] Update results for DAVIS-17 validation set!.",
    "editPermission": {
        "type": "private"
    },
    "function": [
        {
            "operation": [
                {
                    "term": "Quantification",
                    "uri": "http://edamontology.org/operation_3799"
                },
                {
                    "term": "Information extraction",
                    "uri": "http://edamontology.org/operation_3907"
                }
            ]
        }
    ],
    "homepage": "https://github.com/tfzhou/MATNet",
    "language": [
        "Python"
    ],
    "lastUpdate": "2021-02-20T17:17:16Z",
    "name": "MATNet",
    "owner": "Niclaskn",
    "publication": [
        {
            "doi": "10.1109/TIP.2020.3013162",
            "metadata": {
                "abstract": "\u00a9 1992-2012 IEEE.In this paper, we present a novel end-to-end learning neural network, i.e., MATNet, for zero-shot video object segmentation (ZVOS). Motivated by the human visual attention behavior, MATNet leverages motion cues as a bottom-up signal to guide the perception of object appearance. To achieve this, an asymmetric attention block, named Motion-Attentive Transition (MAT), is proposed within a two-stream encoder network to firstly identify moving regions and then attend appearance learning to capture the full extent of objects. Putting MATs in different convolutional layers, our encoder becomes deeply interleaved, allowing for close hierarchical interactions between object apperance and motion. Such a biologically-inspired design is proven to be superb to conventional two-stream structures, which treat motion and appearance independently in separate streams and often suffer severe overfitting to object appearance. Moreover, we introduce a bridge network to modulate multi-scale spatiotemporal features into more compact, discriminative and scale-sensitive representations, which are subsequently fed into a boundary-aware decoder network to produce accurate segmentation with crisp boundaries. We perform extensive quantitative and qualitative experiments on four challenging public benchmarks, i.e., DAVIS16, DAVIS17, FBMS and YouTube-Objects. Results show that our method achieves compelling performance against current state-of-the-art ZVOS methods. To further demonstrate the generalization ability of our spatiotemporal learning framework, we extend MATNet to another relevant task: dynamic visual attention prediction (DVAP). The experiments on two popular datasets (i.e., Hollywood-2 and UCF-Sports) further verify the superiority of our model (our code is available at https://github.com/tfzhou/MATNet).",
                "authors": [
                    {
                        "name": "Zhou T."
                    },
                    {
                        "name": "Li J."
                    },
                    {
                        "name": "Wang S."
                    },
                    {
                        "name": "Tao R."
                    },
                    {
                        "name": "Shen J."
                    }
                ],
                "citationCount": 3,
                "date": "2020-01-01T00:00:00Z",
                "journal": "IEEE Transactions on Image Processing",
                "title": "MATNet: Motion-Attentive Transition Network for Zero-Shot Video Object Segmentation"
            },
            "pmid": "32784135"
        }
    ],
    "toolType": [
        "Command-line tool"
    ],
    "topic": [
        {
            "term": "Machine learning",
            "uri": "http://edamontology.org/topic_3474"
        },
        {
            "term": "Imaging",
            "uri": "http://edamontology.org/topic_3382"
        }
    ]
}
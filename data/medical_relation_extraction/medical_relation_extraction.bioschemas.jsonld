{
  "@context": {
    "biotools": "https://bio.tools/ontology/",
    "bsc": "http://bioschemas.org/",
    "edam": "http://edamontology.org/",
    "rdf": "http://www.w3.org/1999/02/22-rdf-syntax-ns#",
    "rdfs": "http://www.w3.org/2000/01/rdf-schema#",
    "sc": "http://schema.org/",
    "xsd": "http://www.w3.org/2001/XMLSchema#"
  },
  "@graph": [
    {
      "@id": "https://bio.tools/medical_relation_extraction",
      "@type": "sc:SoftwareApplication",
      "sc:additionalType": "Command-line tool",
      "sc:applicationSubCategory": [
        {
          "@id": "edam:topic_3303"
        },
        {
          "@id": "edam:topic_3474"
        },
        {
          "@id": "edam:topic_0218"
        }
      ],
      "sc:citation": [
        {
          "@id": "https://doi.org/10.1093/DATABASE/BAZ116"
        },
        "pmcid:PMC6892305",
        "pubmed:31800044"
      ],
      "sc:description": "A general approach for improving deep learning-based medical relation extraction using a pre-trained model and fine-tuning.\n\nThe depository support training and testing BERT-CNN model on three medical relation extraction corpora: BioCreative V CDR task corpus, traditional Chinese medicine literature corpus, and i2b2 temporal relation corpus.\n\nThis is an implementation of BERT-CNN model used in our paper \"A General Approach for Improving Deep Learning-based Medical Relation Extraction using a Pre-trained Model and Fine-tuning\".",
      "sc:featureList": [
        {
          "@id": "edam:operation_3625"
        },
        {
          "@id": "edam:operation_3907"
        },
        {
          "@id": "edam:operation_3778"
        }
      ],
      "sc:license": "MIT",
      "sc:name": "medical relation extraction",
      "sc:url": "https://github.com/chentao1999/MedicalRelationExtraction"
    },
    {
      "@id": "https://doi.org/10.1093/DATABASE/BAZ116",
      "@type": "sc:CreativeWork"
    }
  ]
}
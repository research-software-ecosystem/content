{
    "additionDate": "2021-01-18T12:36:09Z",
    "biotoolsCURIE": "biotools:l3fnet",
    "biotoolsID": "l3fnet",
    "confidence_flag": "tool",
    "description": "Harnessing Multi-View Perspective of Light Fields for Low-Light Imaging.\n\nLight Field (LF) offers unique advantages such as post-capture refocusing and depth estimation, but low-light conditions, especially during night, severely limit these capabilities.",
    "editPermission": {
        "type": "private"
    },
    "function": [
        {
            "operation": [
                {
                    "term": "Image analysis",
                    "uri": "http://edamontology.org/operation_3443"
                },
                {
                    "term": "Visualisation",
                    "uri": "http://edamontology.org/operation_0337"
                }
            ]
        }
    ],
    "homepage": "https://mohitlamba94.github.io/L3Fnet/",
    "lastUpdate": "2021-02-12T11:08:20Z",
    "name": "L3Fnet",
    "owner": "Niclaskn",
    "publication": [
        {
            "doi": "10.1109/TIP.2020.3045617",
            "metadata": {
                "abstract": "Â© 1992-2012 IEEE.Light Field (LF) offers unique advantages such as post-capture refocusing and depth estimation, but low-light conditions severely limit these capabilities. To restore low-light LFs we should harness the geometric cues present in different LF views, which is not possible using single-frame low-light enhancement techniques. We propose a deep neural network L3Fnet for Low-Light Light Field (L3F) restoration, which not only performs visual enhancement of each LF view but also preserves the epipolar geometry across views. We achieve this by adopting a two-stage architecture for L3Fnet. Stage-I looks at all the LF views to encode the LF geometry. This encoded information is then used in Stage-II to reconstruct each LF view. To facilitate learning-based techniques for low-light LF imaging, we collected a comprehensive LF dataset of various scenes. For each scene, we captured four LFs, one with near-optimal exposure and ISO settings and the others at different levels of low-light conditions varying from low to extreme low-light settings. The effectiveness of the proposed L3Fnet is supported by both visual and numerical comparisons on this dataset. To further analyze the performance of low-light restoration methods, we also propose the L3F-wild dataset that contains LF captured late at night with almost zero lux values. No ground truth is available in this dataset. To perform well on the L3F-wild dataset, any method must adapt to the light level of the captured scene. To do this we use a pre-processing block that makes L3Fnet robust to various degrees of low-light conditions. Lastly, we show that L3Fnet can also be used for low-light enhancement of single-frame images, despite it being engineered for LF data. We do so by converting the single-frame DSLR image into a form suitable to L3Fnet, which we call as pseudo-LF. Our code and dataset is available for download at https://mohitlamba94.github.io/L3Fnet/",
                "authors": [
                    {
                        "name": "Lamba M."
                    },
                    {
                        "name": "Mitra K."
                    },
                    {
                        "name": "Rachavarapu K.K."
                    }
                ],
                "citationCount": 2,
                "date": "2021-01-01T00:00:00Z",
                "journal": "IEEE Transactions on Image Processing",
                "title": "Harnessing Multi-View Perspective of Light Fields for Low-Light Imaging"
            },
            "pmid": "33360991"
        }
    ],
    "toolType": [
        "Command-line tool"
    ],
    "topic": [
        {
            "term": "Imaging",
            "uri": "http://edamontology.org/topic_3382"
        },
        {
            "term": "Machine learning",
            "uri": "http://edamontology.org/topic_3474"
        }
    ]
}

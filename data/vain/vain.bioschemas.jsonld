{
  "@context": {
    "biotools": "https://bio.tools/ontology/",
    "bsc": "http://bioschemas.org/",
    "edam": "http://edamontology.org/",
    "rdf": "http://www.w3.org/1999/02/22-rdf-syntax-ns#",
    "rdfs": "http://www.w3.org/2000/01/rdf-schema#",
    "sc": "http://schema.org/",
    "xsd": "http://www.w3.org/2001/XMLSchema#"
  },
  "@id": "https://bio.tools/vain",
  "@type": "sc:SoftwareApplication",
  "sc:description": "Efficient duplicate rate estimation from subsamples of sequencing libraries.\n\nIn high-throughput sequencing (HTS) projects, the sequenced fragmentsâ€™ duplicate rate is a key quality metric. A high duplicate rate may arise from a low amount of input DNA and many PCR cycles. Many methods for downstream analyses require that duplicates be removed. If the duplicate rate is high, most of the sequencing effort and money spent would have been in vain. Therefore, it is of considerable interest to estimate the duplicate rate after sequencing only a small subsample at low depth (multiplexed with other libraries) for quality control before running the full experiment. In this article, we provide an elementary mathematical framework and an efficient computational approach based on quadratic and linear optimization to estimate the true duplicate rate from a small subsample.\n\n||| HOMEPAGE MISSING!.\n\n||| CORRECT NAME OF TOOL COULD ALSO BE 'up-sampling', 'duplicate', 'inverts', 'subsample'",
  "sc:license": "MIT",
  "sc:name": "vain",
  "sc:url": "https://doi.org/10.7287/PEERJ.PREPRINTS.1298V2"
}
{
    "additionDate": "2021-01-18T12:26:21Z",
    "biotoolsCURIE": "biotools:ffd",
    "biotoolsID": "ffd",
    "confidence_flag": "tool",
    "credit": [
        {
            "email": "yonghuai.liu@edgehill.ac.uk",
            "typeEntity": "Person"
        }
    ],
    "description": "FFD is a fast scale-invariant feature detector for computer vision tasks. Features include extracting matching features across a given pair of images.",
    "editPermission": {
        "type": "private"
    },
    "function": [
        {
            "operation": [
                {
                    "term": "Image analysis",
                    "uri": "http://edamontology.org/operation_3443"
                },
                {
                    "term": "Modelling and simulation",
                    "uri": "http://edamontology.org/operation_2426"
                }
            ]
        }
    ],
    "homepage": "https://github.com/mogvision/FFD",
    "language": [
        "Python"
    ],
    "lastUpdate": "2021-03-10T21:52:34Z",
    "name": "FFD",
    "owner": "Kigaard",
    "publication": [
        {
            "doi": "10.1109/TIP.2020.3042057",
            "metadata": {
                "abstract": "\u00a9 1992-2012 IEEE.Scale-invariance, good localization and robustness to noise and distortions are the main properties that a local feature detector should possess. Most existing local feature detectors find excessive unstable feature points that increase the number of keypoints to be matched and the computational time of the matching step. In this paper, we show that robust and accurate keypoints exist in the specific scale-space domain. To this end, we first formulate the superimposition problem into a mathematical model and then derive a closed-form solution for multiscale analysis. The model is formulated via difference-of-Gaussian (DoG) kernels in the continuous scale-space domain, and it is proved that setting the scale-space pyramid's blurring ratio and smoothness to 2 and 0.627, respectively, facilitates the detection of reliable keypoints. For the applicability of the proposed model to discrete images, we discretize it using the undecimated wavelet transform and the cubic spline function. Theoretically, the complexity of our method is less than 5% of that of the popular baseline Scale Invariant Feature Transform (SIFT). Extensive experimental results show the superiority of the proposed feature detector over the existing representative hand-crafted and learning-based techniques in accuracy and computational time. The code and supplementary materials can be found at https://github.com/mogvision/FFD.",
                "authors": [
                    {
                        "name": "Ghahremani M."
                    },
                    {
                        "name": "Liu Y."
                    },
                    {
                        "name": "Tiddeman B."
                    }
                ],
                "citationCount": 5,
                "date": "2021-01-01T00:00:00Z",
                "journal": "IEEE Transactions on Image Processing",
                "title": "FFD: Fast Feature Detector"
            },
            "pmid": "33306465"
        }
    ],
    "toolType": [
        "Command-line tool"
    ],
    "topic": [
        {
            "term": "Imaging",
            "uri": "http://edamontology.org/topic_3382"
        },
        {
            "term": "Mathematics",
            "uri": "http://edamontology.org/topic_3315"
        }
    ]
}
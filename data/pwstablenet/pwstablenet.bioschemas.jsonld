{
  "@context": {
    "biotools": "https://bio.tools/ontology/",
    "bsc": "http://bioschemas.org/",
    "bsct": "http://bioschemas.org/types/",
    "dct": "http://purl.org/dc/terms/",
    "edam": "http://edamontology.org/",
    "rdf": "http://www.w3.org/1999/02/22-rdf-syntax-ns#",
    "rdfs": "http://www.w3.org/2000/01/rdf-schema#",
    "sc": "http://schema.org/",
    "xsd": "http://www.w3.org/2001/XMLSchema#"
  },
  "@graph": [
    {
      "@id": "https://bio.tools/pwstablenet",
      "@type": "sc:SoftwareApplication",
      "dct:conformsTo": "https://bioschemas.org/profiles/ComputationalTool/0.6-DRAFT",
      "sc:applicationSubCategory": {
        "@id": "edam:topic_0102"
      },
      "sc:citation": [
        "pubmed:31944957",
        {
          "@id": "https://doi.org/10.1109/TIP.2019.2963380"
        }
      ],
      "sc:description": "Learning Pixel-wise Warping Maps for Video Stabilization.\n\nAs the videos captured by hand-held cameras are often perturbed by high-frequency jitters, stabilization of these videos is an essential task. Many video stabilization methods have been proposed to stabilize shaky videos. However, most methods estimate one global homography or several homographies based on fixed meshes to warp the shaky frames into their stabilized views. Due to the existence of parallax, such single or a few homographies can not well handle the depth variation. In contrast to these traditional methods, we propose a novel video stabilization network, called PWStableNet, which comes up pixel-wise warping maps, i.e., potentially different warping for different pixels, and stabilizes each pixel to its stabilized view. To our best knowledge, this is the first deep learning based pixel-wise video stabilization",
      "sc:featureList": {
        "@id": "edam:operation_2429"
      },
      "sc:name": "PWStableNet",
      "sc:url": "https://github.com/mindazhao/PWStableNet"
    },
    {
      "@id": "https://doi.org/10.1109/TIP.2019.2963380",
      "@type": "sc:CreativeWork"
    }
  ]
}
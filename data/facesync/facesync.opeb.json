{"credit":[{"email":"jcheong0428@gmail.com","name":"Jin Hyun Cheong","typeEntity":"Person","typeRoles":["Primary contact"]}],"documentation":[{"type":"GENERAL","url":"https://github.com/cosanlab/facesync/blob/master/README.md"}],"download":[{"type":"Source code","url":"https://github.com/cosanlab/facesync/releases"}],"function":[{"operation":[{"term":"Sequence trimming","uri":"http://edamontology.org/operation_3192"}]}],"labels":{"accessibility":["Open access"],"cost":"Free of charge","language":["Python"],"license":"MIT","maturity":"Mature","operatingSystem":["Linux","Mac"],"toolType":["Library"],"topic":[{"term":"Machine learning","uri":"http://edamontology.org/topic_3474"},{"term":"RNA immunoprecipitation","uri":"http://edamontology.org/topic_3794"}]},"publication":[{"doi":"10.12688/F1000RESEARCH.18187.1","type":"Primary"}],"summary":{"biotoolsCURIE":"biotools:FaceSync","biotoolsID":"FaceSync","description":"Open source framework for recording facial expressions with head-mounted cameras | The FaceSync toolbox provides 3D blueprints for building the head-mounted camera setup described in our paper. The toolbox also provides functions to automatically synchronize videos based on audio, manually align audio, plot facial landmark movements, and inspect synchronized videos to graph data","homepage":"https://github.com/cosanlab/facesync","name":"FaceSync"}}
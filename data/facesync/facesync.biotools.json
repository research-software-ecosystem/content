{
    "accessibility": "Open access",
    "additionDate": "2019-08-09T13:14:35Z",
    "biotoolsCURIE": "biotools:FaceSync",
    "biotoolsID": "FaceSync",
    "cost": "Free of charge",
    "credit": [
        {
            "email": "jcheong0428@gmail.com",
            "name": "Jin Hyun Cheong",
            "typeEntity": "Person",
            "typeRole": [
                "Primary contact"
            ]
        }
    ],
    "description": "Open source framework for recording facial expressions with head-mounted cameras | The FaceSync toolbox provides 3D blueprints for building the head-mounted camera setup described in our paper. The toolbox also provides functions to automatically synchronize videos based on audio, manually align audio, plot facial landmark movements, and inspect synchronized videos to graph data",
    "documentation": [
        {
            "type": [
                "General"
            ],
            "url": "https://github.com/cosanlab/facesync/blob/master/README.md"
        }
    ],
    "download": [
        {
            "type": "Source code",
            "url": "https://github.com/cosanlab/facesync/releases"
        }
    ],
    "editPermission": {
        "type": "private"
    },
    "function": [
        {
            "operation": [
                {
                    "term": "Sequence trimming",
                    "uri": "http://edamontology.org/operation_3192"
                }
            ]
        }
    ],
    "homepage": "https://github.com/cosanlab/facesync",
    "language": [
        "Python"
    ],
    "lastUpdate": "2020-06-16T10:55:25Z",
    "license": "MIT",
    "maturity": "Mature",
    "name": "FaceSync",
    "operatingSystem": [
        "Linux",
        "Mac"
    ],
    "owner": "hans",
    "publication": [
        {
            "doi": "10.12688/F1000RESEARCH.18187.1",
            "metadata": {
                "abstract": "\u00a9 2019 Cheong JH et al.Advances in computer vision and machine learning algorithms have enabled researchers to extract facial expression data from face video recordings with greater ease and speed than standard manual coding methods, which has led to a dramatic increase in the pace of facial expression research. However, there are many limitations in recording facial expressions in laboratory settings. Conventional video recording setups using webcams, tripod-mounted cameras, or pan-tilt-zoom cameras require making compromises between cost, reliability, and flexibility. As an alternative, we propose the use of a mobile head-mounted camera that can be easily constructed from our open-source instructions and blueprints at a fraction of the cost of conventional setups. The head-mounted camera framework is supported by the open source Python toolbox FaceSync, which provides an automated method for synchronizing videos. We provide four proof-of-concept studies demonstrating the benefits of this recording system in reliably measuring and analyzing facial expressions in diverse experimental setups, including group interaction experiments.",
                "authors": [
                    {
                        "name": "Cheong J.H."
                    },
                    {
                        "name": "Brooks S."
                    },
                    {
                        "name": "Chang L.J."
                    }
                ],
                "citationCount": 1,
                "date": "2019-01-01T00:00:00Z",
                "journal": "F1000Research",
                "title": "FaceSync: Open source framework for recording facial expressions with head-mounted cameras [version 1; peer review: 1 approved]"
            },
            "type": [
                "Primary"
            ]
        }
    ],
    "toolType": [
        "Library"
    ],
    "topic": [
        {
            "term": "Machine learning",
            "uri": "http://edamontology.org/topic_3474"
        },
        {
            "term": "RNA immunoprecipitation",
            "uri": "http://edamontology.org/topic_3794"
        }
    ],
    "validated": 1
}
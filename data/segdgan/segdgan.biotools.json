{
    "additionDate": "2021-01-18T11:35:52Z",
    "biotoolsCURIE": "biotools:segdgan",
    "biotoolsID": "segdgan",
    "confidence_flag": "tool",
    "description": "Automatic segmentation of prostate magnetic resonance imaging using generative adversarial networks.\n\nThis repository is the official repository of the article \"Automatic Segmentation of Prostate Magnetic Resonance Imaging Using Generative Adversarial Networks\" To train a model use the train.py file, you can use the following commands line to get the important arguments.\n\nYou can config the detailed parameters in the config.py.\n\nTo do the inference, use the test.py file, you can use the following commands line to get the important arguments.",
    "editPermission": {
        "type": "private"
    },
    "function": [
        {
            "operation": [
                {
                    "term": "Network analysis",
                    "uri": "http://edamontology.org/operation_3927"
                },
                {
                    "term": "Quantification",
                    "uri": "http://edamontology.org/operation_3799"
                },
                {
                    "term": "Feature extraction",
                    "uri": "http://edamontology.org/operation_3937"
                }
            ]
        }
    ],
    "homepage": "https://github.com/w3user/SegDGAN",
    "language": [
        "Python"
    ],
    "lastUpdate": "2021-02-16T13:56:40Z",
    "name": "SegDGAN",
    "owner": "zsmag19",
    "publication": [
        {
            "doi": "10.1016/J.CLINIMAG.2020.10.014",
            "metadata": {
                "abstract": "\u00a9 2020Background: Automatic and detailed segmentation of the prostate using magnetic resonance imaging (MRI) plays an essential role in prostate imaging diagnosis. Traditionally, prostate gland was manually delineated by the clinician in a time-consuming process that requires professional experience of the observer. Thus, we proposed an automatic prostate segmentation method, called SegDGAN, which is based on a classic generative adversarial network model. Material and methods: The proposed method comprises a fully convolutional generation network of densely con- nected blocks and a critic network with multi-scale feature extraction. In these computations, the objective function is optimized using mean absolute error and the Dice coefficient, leading to improved accuracy of segmentation results and correspondence with the ground truth. The common and similar medical image segmentation networks U-Net, FCN, and SegAN were selected for qualitative and quantitative comparisons with SegDGAN using a 220-patient dataset and the public datasets. The commonly used segmentation evaluation metrics DSC, VOE, ASD, and HD were used to compare the accuracy of segmentation between these methods. Results: SegDGAN achieved the highest DSC value of 91.66%, the lowest VOE value of 15.28%, the lowest ASD values of 0.51 mm and the lowest HD value of 11.58 mm with the clinical dataset. In addition, the highest DSC value, and the lowest VOE, ASD and HD values obtained with the public data set PROMISE12 were 86.24%, 23.60%, 1.02 mm and 7.57 mm, respectively. Conclusions: Our experimental results show that the SegDGAN model have the potential to improve the accuracy of MRI-based prostate gland segmentation. Code has been made available at: https://github.com/w3user/SegDGAN",
                "authors": [
                    {
                        "name": "Wang W."
                    },
                    {
                        "name": "Wang G."
                    },
                    {
                        "name": "Wu X."
                    },
                    {
                        "name": "Ding X."
                    },
                    {
                        "name": "Cao X."
                    },
                    {
                        "name": "Wang L."
                    },
                    {
                        "name": "Zhang J."
                    },
                    {
                        "name": "Wang P."
                    }
                ],
                "citationCount": 3,
                "date": "2021-02-01T00:00:00Z",
                "journal": "Clinical Imaging",
                "title": "Automatic segmentation of prostate magnetic resonance imaging using generative adversarial networks"
            },
            "pmid": "33120283"
        }
    ],
    "topic": [
        {
            "term": "MRI",
            "uri": "http://edamontology.org/topic_3444"
        },
        {
            "term": "Medical imaging",
            "uri": "http://edamontology.org/topic_3384"
        },
        {
            "term": "Medicine",
            "uri": "http://edamontology.org/topic_3303"
        }
    ]
}
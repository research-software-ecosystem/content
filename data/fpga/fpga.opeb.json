{"credit":[{"email":"wuyanxia@hrbeu.edu.cn","name":"Yanxia Wu","typeEntity":"Person","typeRoles":[]}],"labels":{"language":["C"],"topic":[{"term":"Machine learning","uri":"http://edamontology.org/topic_3474"},{"term":"Software engineering","uri":"http://edamontology.org/topic_3372"},{"term":"Laboratory techniques","uri":"http://edamontology.org/topic_3361"}]},"publication":[{"doi":"10.1371/JOURNAL.PONE.0222984","pmcid":"PMC6786543","pmid":"31600218"}],"summary":{"biotoolsCURIE":"biotools:FPGA","biotoolsID":"FPGA","description":"Research on OpenCL optimization for FPGA deep learning application.\n\nOptimize the code provided by Xilinx, and the experiment proves that the optimized performance is 8-40 times optimized by Xilinx.The code URL provided by Xilinx is: https://github.com/Xilinx/SDAccel_Examples/tree/master/getting_started/clk_freq/large_loop_ocl Eight kinds Of convolution layer programs are set up by us according to the ascending order.\n\n||| CORRECT NAME OF TOOL COULD ALSO BE 'OpenCL'","homepage":"https://github.com/PoetryAndWine/FPGA_CNN_Acceleration","name":"FPGA"}}